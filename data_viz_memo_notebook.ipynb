{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Heart of Capital Punishment: Execution trends in the American South\n",
    "#### FACE EXTRACTION CROP OF EXECUTED DEATH ROW CONVICTS IN TEXAS\n",
    "\n",
    "This project aims to visualize relevant trends in the significance and character of Texas' capital punishment system. In the effort of humanizing the statistics presented, I extracted and captured the images of the individuals executed by the Texas Department of Criminal Justice from the agency's <a href='https://www.tdcj.texas.gov/death_row/dr_executed_offenders.html'>Death Row Information</a> database. \n",
    "\n",
    "\n",
    "The final visualization can be found <a href='https://public.flourish.studio/story/622962/'>here</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the <a href='https://chrome.google.com/webstore/detail/web-scraper-free-web-scra/jnhgnonknehpejjnehehllkliplmbmhn'> West Scraper</a> extension to extract image links of the convicts from the TDCJ's website. The tool renders the data in CSV format. I manually cleaned the data before uploading it into Jupyter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"executions_texas_images.csv\")\n",
    "\n",
    "urls = list(data.image_url_clean)  # creating list of image urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image urls led to two different image formats, as shown below.\n",
    "\n",
    "#### FORMAT 1:\n",
    "<img src=\"example_1.jpg\" width=\"100\" height=\"300\"/>\n",
    "\n",
    "#### FORMAT 2:\n",
    "<img src=\"example_2.jpg\" width=\"100\" height=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the mugshots from images of format 2, I first used the SHUTIL library to save the images locally from the image urls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found = []  # generating list of missing images\n",
    "\n",
    "for image_url in urls:\n",
    "    if image_url[-5:] != \"2.jpg\":\n",
    "        filename = image_url.split(\"/\")[-1]   # generating filename\n",
    "        r = requests.get(image_url, stream = True)  # getting image url\n",
    "        if r.status_code == 200:  # verifying image existence\n",
    "            r.raw.decode_content = True\n",
    "            found.append(filename)\n",
    "            with open(filename,'wb') as f:\n",
    "                shutil.copyfileobj(r.raw, f)  # saving image locally\n",
    "        else:\n",
    "            not_found.append(filename)  \n",
    "            \n",
    "not_found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I used the CV2 Library to identify and extract the convict's faces as new images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"images\"):\n",
    "    image = cv2.imread(os.path.join(\"images\",filename))  # reading image\n",
    "    name = filename[:-4]  # setting filename\n",
    "    print(name)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # setting grayscale\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")  # detecting face\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3)\n",
    "\n",
    "    print(\"[INFO] Found {0} Faces!\".format(len(faces)))\n",
    "\n",
    "    for (x, y, w, h) in faces:  # extracting face\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (128, 128, 128), 2)\n",
    "        roi_color = image[y:y + h, x:x + w] \n",
    "        print(\"[INFO] Object found. Saving locally.\") \n",
    "        cv2.imwrite(name + '_face.jpg', roi_color)  # saving locally"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
